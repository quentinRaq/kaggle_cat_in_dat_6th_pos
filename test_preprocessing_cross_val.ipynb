{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T16:53:26.893168Z",
     "start_time": "2018-10-30T16:53:26.735211Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('cat_in_dat/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cat_in_dat/train_cat_kaggle.csv')\n",
    "test = pd.read_csv('cat_in_dat/test_cat_kaggle.csv')\n",
    "y_test = pd.read_csv('cat_in_dat/y_test_cat_kaggle.csv', header=None).values.flatten()\n",
    "y_train = train['target'].values.flatten()\n",
    "train.drop(['target'], axis=1, inplace=True)\n",
    "ntrain = train.shape[0]\n",
    "y = np.hstack([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.concat([train, test])\n",
    "train_test.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['ord_5_1'] = train_test['ord_5'].apply(lambda x: x[0] if type(x) == str else np.nan)\n",
    "train_test['ord_5_2'] = train_test['ord_5'].apply(lambda x: x[1] if type(x) == str else np.nan)\n",
    "train_test['ord_5_1_u'] = train_test['ord_5_1'].apply(lambda x: (x.upper() == x)*1 if type(x) == str else np.nan)\n",
    "train_test['ord_5_2_u'] = train_test['ord_5_2'].apply(lambda x: (x.upper() == x)*1 if type(x) == str else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting ordinal labels into ordered values\n",
    "ord_1 = {\n",
    "    'Novice' : 0,\n",
    "    'Contributor' : 1,\n",
    "    'Expert' : 2,\n",
    "    'Master' : 3,\n",
    "    'Grandmaster' : 4\n",
    "}\n",
    "\n",
    "ord_2 = {\n",
    "    'Freezing' : 0,\n",
    "    'Cold' : 1,\n",
    "    'Warm' : 2,\n",
    "    'Hot' : 3,\n",
    "    'Boiling Hot' : 4,\n",
    "    'Lava Hot' : 5\n",
    "}\n",
    "\n",
    "train_test['ord_1'] = train_test['ord_1'].map(ord_1)\n",
    "train_test['ord_2'] = train_test['ord_2'].map(ord_2)\n",
    "train_test['num_nan_count'] = train_test.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_col = [col for col in train_test.columns if col.startswith('bin_')]\n",
    "nom_col = [col for col in train_test.columns if col.startswith('nom_')]\n",
    "nom_col_low = [c for c in nom_col if len(train_test[c].unique()) <= 10]\n",
    "nom_col_high = [c for c in nom_col if len(train_test[c].unique()) > 10]\n",
    "ord_col = [col for col in train_test.columns if col.startswith('ord_')]\n",
    "num_col = [col for col in train_test.columns if col.startswith('num_')]\n",
    "all_cat_columns = [col for col in train_test.columns if col not in num_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cat boost encoder\n",
    "for col in nom_col_high:\n",
    "    fill_value = -1\n",
    "    if train_test[col].dtype == 'O':\n",
    "        fill_value = 'missing'\n",
    "    si = SimpleImputer(strategy='constant', fill_value=fill_value)\n",
    "    tr = CatBoostEncoder()\n",
    "    temp = si.fit_transform(train_test[col].values.reshape(-1, 1))\n",
    "    tr.fit(temp[:ntrain], y_train)\n",
    "    train_test[col + '_te'] = tr.transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Label encoder\n",
    "for col in ord_col:\n",
    "    fill_value = -1\n",
    "    if train_test[col].dtype == 'O':\n",
    "        fill_value = 'missing'\n",
    "    si = SimpleImputer(strategy='constant', fill_value=fill_value)\n",
    "    tr = LabelEncoder()\n",
    "    temp = si.fit_transform(train_test[col].values.reshape(-1, 1))\n",
    "    train_test[col + '_le'] = tr.fit_transform(temp.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# One hot encoder\n",
    "for col in bin_col + nom_col_low + ['day'] + ['month']:\n",
    "    fill_value = -1\n",
    "    if train_test[col].dtype == 'O':\n",
    "        fill_value = 'missing'\n",
    "    si = SimpleImputer(strategy='constant', fill_value=fill_value)\n",
    "    tr = OneHotEncoder(categories='auto', sparse=False)\n",
    "    temp = si.fit_transform(train_test[col].values.reshape(-1, 1))\n",
    "    temp = tr.fit_transform(temp.reshape(-1, 1))\n",
    "    columns = [col + '_' + col_names for col_names in tr.get_feature_names()]\n",
    "    res = pd.DataFrame(temp, columns=columns)\n",
    "    train_test = pd.concat([train_test.reset_index(drop=True), res.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Freq encoding\n",
    "for col in nom_col:\n",
    "    fill_value = -1\n",
    "    if train_test[col].dtype == 'O':\n",
    "        fill_value = 'missing'\n",
    "    si = SimpleImputer(strategy='constant', fill_value=fill_value)\n",
    "    temp = pd.Series(si.fit_transform(train_test[col].values.reshape(-1, 1)).flatten())\n",
    "    frequencies = temp.value_counts().to_dict()\n",
    "    train_test[col + '_freq'] = temp.map(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.drop(all_cat_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_test.iloc[:ntrain]\n",
    "test = train_test.iloc[ntrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'n_estimators': 10000,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': 1,\n",
    "    'patience': 20,\n",
    "    'random_state': 0,\n",
    "    'tree_method': 'gpu_hist'\n",
    "}\n",
    "\n",
    "grid_params = {\n",
    "    'learning_rate': [.01, .05, .1],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [.6, .7, .8, .9],\n",
    "    'colsample_bytree': [.6, .7, .8, .9, 1.0],\n",
    "    'reg_lambda': [.01, .025, .05, .075, .1, .5],\n",
    "    'reg_alpha': [0., .01, .025, .05, .1, .5],\n",
    "    'gamma': [.05, .075, .1, .3, .5, .7, 1.]\n",
    "}\n",
    "\n",
    "list_params = list(ParameterSampler(grid_params,\n",
    "                                    n_iter=20,\n",
    "                                    random_state=0))\n",
    "\n",
    "for param in list_params:\n",
    "    param.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "aucs = []\n",
    "clfs_grid = []\n",
    "for param in list_params:\n",
    "    print(param)\n",
    "    clf = XGBClassifier(**param)\n",
    "    clf.fit(train.values, y_train,\n",
    "        eval_set=[(train.values, y_train), (test.values, y_test)],\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=params['patience'],\n",
    "        verbose=5)\n",
    "    prediction = clf.predict_proba(test.values)\n",
    "    auc = roc_auc_score(y_test, prediction[: ,1])\n",
    "    aucs.append(auc)\n",
    "    clfs_grid.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip(aucs, list_params):\n",
    "    print(i)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'subsample': 0.7,\n",
    "    'reg_lambda': 0.075,\n",
    "    'reg_alpha': 0.01,\n",
    "    'min_child_weight': 5,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.01,\n",
    "    'gamma': 0.5,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'binary:logistic',\n",
    "    'n_estimators': 10000,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': 1,\n",
    "    'patience': 20,\n",
    "    'random_state': 0,\n",
    "    'tree_method': 'gpu_hist'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "clfs = []\n",
    "predictions = []\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, valid_index in skf.split(train.values, y_train):\n",
    "    X_train = train.values[train_index]\n",
    "    Y_train = y_train[train_index]\n",
    "    X_valid = train.values[valid_index]\n",
    "    Y_valid = y_train[valid_index]\n",
    "    clf = XGBClassifier(**best_params)\n",
    "    clf.fit(X_train, Y_train,\n",
    "            eval_set=[(X_train, Y_train), (X_valid, Y_valid)],\n",
    "            eval_metric='auc',\n",
    "            early_stopping_rounds=best_params['patience'],\n",
    "            verbose=5)\n",
    "    clfs.append(clf)\n",
    "    prediction = clf.predict_proba(test.values)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "test_predictions = np.array(predictions).mean(axis=0)[:, 1]\n",
    "auc = roc_auc_score(y_test, test_predictions)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_col_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline  \n",
    "imp = pd.DataFrame(clf.feature_importances_, index=train.columns, columns=['Feature_importance'])\n",
    "imp.sort_values('Feature_importance').plot(kind='barh', figsize=(8,20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
