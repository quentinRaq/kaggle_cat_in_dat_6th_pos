{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T16:53:26.893168Z",
     "start_time": "2018-10-30T16:53:26.735211Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from copy import copy\n",
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cat_in_dat/train.csv')\n",
    "test = pd.read_csv('cat_in_dat/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"target\"] = -1\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "\n",
    "# Converting ordinal labels into ordered values\n",
    "ord_1 = {\n",
    "    'Novice' : 0,\n",
    "    'Contributor' : 1,\n",
    "    'Expert' : 2,\n",
    "    'Master' : 3,\n",
    "    'Grandmaster' : 4\n",
    "}\n",
    "\n",
    "ord_2 = {\n",
    "    'Freezing' : 0,\n",
    "    'Cold' : 1,\n",
    "    'Warm' : 2,\n",
    "    'Hot' : 3,\n",
    "    'Boiling Hot' : 4,\n",
    "    'Lava Hot' : 5\n",
    "}\n",
    "\n",
    "data['ord_1'] = data['ord_1'].map(ord_1)\n",
    "data['ord_2'] = data['ord_2'].map(ord_2)\n",
    "\n",
    "bin_col = [col for col in data.columns if col.startswith('bin_')]\n",
    "nom_col = [col for col in data.columns if col.startswith('nom_')]\n",
    "nom_col_low = [c for c in nom_col if len(data[c].unique()) <= 20]\n",
    "nom_col_high = [c for c in nom_col if len(data[c].unique()) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.05 s, sys: 2.02 s, total: 9.06 s\n",
      "Wall time: 9.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# One hot encoder\n",
    "for col in bin_col + nom_col_low + ['day'] + ['month']:\n",
    "    fill_value = -1\n",
    "    if data[col].dtype == 'O':\n",
    "        fill_value = 'missing'\n",
    "    si = SimpleImputer(strategy='constant', fill_value=fill_value)\n",
    "    tr = preprocessing.OneHotEncoder(categories='auto', sparse=False)\n",
    "    temp = si.fit_transform(data[col].values.reshape(-1, 1))\n",
    "    temp = tr.fit_transform(temp.reshape(-1, 1))\n",
    "    columns = [col + '_' + col_names for col_names in tr.get_feature_names()]\n",
    "    res = pd.DataFrame(temp, columns=columns)\n",
    "    data = pd.concat([data.reset_index(drop=True), res.reset_index(drop=True)], axis=1)\n",
    "    data.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in data.columns if x not in [\"id\", \"target\"]]\n",
    "for feat in features:\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    data[feat] = lbl_enc.fit_transform(data[feat].fillna(\"-1\").astype(str).values)\n",
    "    ss = preprocessing.StandardScaler()\n",
    "    data[feat] = ss.fit_transform(data[feat].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nom_5</th>\n",
       "      <th>nom_6</th>\n",
       "      <th>nom_7</th>\n",
       "      <th>nom_8</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>target</th>\n",
       "      <th>bin_0_x0_-1.0</th>\n",
       "      <th>bin_0_x0_0.0</th>\n",
       "      <th>bin_0_x0_1.0</th>\n",
       "      <th>bin_1_x0_-1.0</th>\n",
       "      <th>bin_1_x0_0.0</th>\n",
       "      <th>bin_1_x0_1.0</th>\n",
       "      <th>bin_2_x0_-1.0</th>\n",
       "      <th>bin_2_x0_0.0</th>\n",
       "      <th>bin_2_x0_1.0</th>\n",
       "      <th>bin_3_x0_F</th>\n",
       "      <th>bin_3_x0_T</th>\n",
       "      <th>bin_3_x0_missing</th>\n",
       "      <th>bin_4_x0_N</th>\n",
       "      <th>bin_4_x0_Y</th>\n",
       "      <th>bin_4_x0_missing</th>\n",
       "      <th>nom_0_x0_Blue</th>\n",
       "      <th>nom_0_x0_Green</th>\n",
       "      <th>nom_0_x0_Red</th>\n",
       "      <th>nom_0_x0_missing</th>\n",
       "      <th>nom_1_x0_Circle</th>\n",
       "      <th>nom_1_x0_Polygon</th>\n",
       "      <th>nom_1_x0_Square</th>\n",
       "      <th>nom_1_x0_Star</th>\n",
       "      <th>nom_1_x0_Trapezoid</th>\n",
       "      <th>nom_1_x0_Triangle</th>\n",
       "      <th>nom_1_x0_missing</th>\n",
       "      <th>nom_2_x0_Axolotl</th>\n",
       "      <th>nom_2_x0_Cat</th>\n",
       "      <th>nom_2_x0_Dog</th>\n",
       "      <th>nom_2_x0_Hamster</th>\n",
       "      <th>nom_2_x0_Lion</th>\n",
       "      <th>nom_2_x0_Snake</th>\n",
       "      <th>nom_2_x0_missing</th>\n",
       "      <th>nom_3_x0_Canada</th>\n",
       "      <th>nom_3_x0_China</th>\n",
       "      <th>nom_3_x0_Costa Rica</th>\n",
       "      <th>nom_3_x0_Finland</th>\n",
       "      <th>nom_3_x0_India</th>\n",
       "      <th>nom_3_x0_Russia</th>\n",
       "      <th>nom_3_x0_missing</th>\n",
       "      <th>nom_4_x0_Bassoon</th>\n",
       "      <th>nom_4_x0_Oboe</th>\n",
       "      <th>nom_4_x0_Piano</th>\n",
       "      <th>nom_4_x0_Theremin</th>\n",
       "      <th>nom_4_x0_missing</th>\n",
       "      <th>day_x0_-1.0</th>\n",
       "      <th>day_x0_1.0</th>\n",
       "      <th>day_x0_2.0</th>\n",
       "      <th>day_x0_3.0</th>\n",
       "      <th>day_x0_4.0</th>\n",
       "      <th>day_x0_5.0</th>\n",
       "      <th>day_x0_6.0</th>\n",
       "      <th>day_x0_7.0</th>\n",
       "      <th>month_x0_-1.0</th>\n",
       "      <th>month_x0_1.0</th>\n",
       "      <th>month_x0_2.0</th>\n",
       "      <th>month_x0_3.0</th>\n",
       "      <th>month_x0_4.0</th>\n",
       "      <th>month_x0_5.0</th>\n",
       "      <th>month_x0_6.0</th>\n",
       "      <th>month_x0_7.0</th>\n",
       "      <th>month_x0_8.0</th>\n",
       "      <th>month_x0_9.0</th>\n",
       "      <th>month_x0_10.0</th>\n",
       "      <th>month_x0_11.0</th>\n",
       "      <th>month_x0_12.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.311572</td>\n",
       "      <td>0.616130</td>\n",
       "      <td>-0.282442</td>\n",
       "      <td>-1.642618</td>\n",
       "      <td>-1.597645</td>\n",
       "      <td>1.226857</td>\n",
       "      <td>-0.434369</td>\n",
       "      <td>0.579122</td>\n",
       "      <td>-0.918435</td>\n",
       "      <td>1.038410</td>\n",
       "      <td>-0.569633</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.175243</td>\n",
       "      <td>0.369005</td>\n",
       "      <td>-0.314583</td>\n",
       "      <td>-0.175987</td>\n",
       "      <td>0.516557</td>\n",
       "      <td>-0.469454</td>\n",
       "      <td>-0.175567</td>\n",
       "      <td>0.654898</td>\n",
       "      <td>-0.608557</td>\n",
       "      <td>0.799079</td>\n",
       "      <td>-0.749562</td>\n",
       "      <td>-0.175757</td>\n",
       "      <td>0.959286</td>\n",
       "      <td>-0.903130</td>\n",
       "      <td>-0.175857</td>\n",
       "      <td>-0.721667</td>\n",
       "      <td>-0.309652</td>\n",
       "      <td>0.923445</td>\n",
       "      <td>-0.17681</td>\n",
       "      <td>-0.460679</td>\n",
       "      <td>-0.583435</td>\n",
       "      <td>-0.214282</td>\n",
       "      <td>-0.155731</td>\n",
       "      <td>2.003362</td>\n",
       "      <td>-0.614078</td>\n",
       "      <td>-0.176174</td>\n",
       "      <td>-0.583748</td>\n",
       "      <td>-0.214323</td>\n",
       "      <td>-0.460171</td>\n",
       "      <td>1.626968</td>\n",
       "      <td>-0.498759</td>\n",
       "      <td>-0.155333</td>\n",
       "      <td>-0.176509</td>\n",
       "      <td>-0.214647</td>\n",
       "      <td>-0.155866</td>\n",
       "      <td>-0.582391</td>\n",
       "      <td>-0.459270</td>\n",
       "      <td>-0.615181</td>\n",
       "      <td>2.000419</td>\n",
       "      <td>-0.176759</td>\n",
       "      <td>1.431019</td>\n",
       "      <td>-0.301501</td>\n",
       "      <td>-0.215507</td>\n",
       "      <td>-1.028728</td>\n",
       "      <td>-0.175948</td>\n",
       "      <td>-0.175794</td>\n",
       "      <td>-0.405564</td>\n",
       "      <td>-0.350332</td>\n",
       "      <td>-0.484009</td>\n",
       "      <td>-0.202636</td>\n",
       "      <td>-0.475081</td>\n",
       "      <td>2.275033</td>\n",
       "      <td>-0.410403</td>\n",
       "      <td>-0.175778</td>\n",
       "      <td>-0.308234</td>\n",
       "      <td>-0.26932</td>\n",
       "      <td>2.74025</td>\n",
       "      <td>-0.157424</td>\n",
       "      <td>-0.360126</td>\n",
       "      <td>-0.334774</td>\n",
       "      <td>-0.312772</td>\n",
       "      <td>-0.390846</td>\n",
       "      <td>-0.187813</td>\n",
       "      <td>-0.060459</td>\n",
       "      <td>-0.305435</td>\n",
       "      <td>-0.358131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.022687</td>\n",
       "      <td>-0.850450</td>\n",
       "      <td>-1.188238</td>\n",
       "      <td>-0.614555</td>\n",
       "      <td>1.588644</td>\n",
       "      <td>1.226857</td>\n",
       "      <td>1.606769</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>-0.517297</td>\n",
       "      <td>1.424121</td>\n",
       "      <td>1.089410</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.175243</td>\n",
       "      <td>-2.709989</td>\n",
       "      <td>3.178808</td>\n",
       "      <td>-0.175987</td>\n",
       "      <td>-1.935894</td>\n",
       "      <td>2.130133</td>\n",
       "      <td>-0.175567</td>\n",
       "      <td>0.654898</td>\n",
       "      <td>-0.608557</td>\n",
       "      <td>0.799079</td>\n",
       "      <td>-0.749562</td>\n",
       "      <td>-0.175757</td>\n",
       "      <td>-1.042442</td>\n",
       "      <td>1.107261</td>\n",
       "      <td>-0.175857</td>\n",
       "      <td>-0.721667</td>\n",
       "      <td>-0.309652</td>\n",
       "      <td>0.923445</td>\n",
       "      <td>-0.17681</td>\n",
       "      <td>-0.460679</td>\n",
       "      <td>-0.583435</td>\n",
       "      <td>-0.214282</td>\n",
       "      <td>6.421316</td>\n",
       "      <td>-0.499161</td>\n",
       "      <td>-0.614078</td>\n",
       "      <td>-0.176174</td>\n",
       "      <td>1.713069</td>\n",
       "      <td>-0.214323</td>\n",
       "      <td>-0.460171</td>\n",
       "      <td>-0.614640</td>\n",
       "      <td>-0.498759</td>\n",
       "      <td>-0.155333</td>\n",
       "      <td>-0.176509</td>\n",
       "      <td>-0.214647</td>\n",
       "      <td>-0.155866</td>\n",
       "      <td>-0.582391</td>\n",
       "      <td>-0.459270</td>\n",
       "      <td>-0.615181</td>\n",
       "      <td>-0.499895</td>\n",
       "      <td>5.657435</td>\n",
       "      <td>-0.698803</td>\n",
       "      <td>-0.301501</td>\n",
       "      <td>-0.215507</td>\n",
       "      <td>0.972074</td>\n",
       "      <td>-0.175948</td>\n",
       "      <td>-0.175794</td>\n",
       "      <td>-0.405564</td>\n",
       "      <td>-0.350332</td>\n",
       "      <td>-0.484009</td>\n",
       "      <td>-0.202636</td>\n",
       "      <td>-0.475081</td>\n",
       "      <td>-0.439554</td>\n",
       "      <td>2.436631</td>\n",
       "      <td>-0.175778</td>\n",
       "      <td>-0.308234</td>\n",
       "      <td>-0.26932</td>\n",
       "      <td>-0.36493</td>\n",
       "      <td>-0.157424</td>\n",
       "      <td>-0.360126</td>\n",
       "      <td>-0.334774</td>\n",
       "      <td>3.197219</td>\n",
       "      <td>-0.390846</td>\n",
       "      <td>-0.187813</td>\n",
       "      <td>-0.060459</td>\n",
       "      <td>-0.305435</td>\n",
       "      <td>-0.358131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.764437</td>\n",
       "      <td>-0.099220</td>\n",
       "      <td>-0.237152</td>\n",
       "      <td>-0.115642</td>\n",
       "      <td>-1.640435</td>\n",
       "      <td>1.226857</td>\n",
       "      <td>-1.795128</td>\n",
       "      <td>-1.141747</td>\n",
       "      <td>1.287828</td>\n",
       "      <td>0.395558</td>\n",
       "      <td>0.295188</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.175243</td>\n",
       "      <td>0.369005</td>\n",
       "      <td>-0.314583</td>\n",
       "      <td>-0.175987</td>\n",
       "      <td>-1.935894</td>\n",
       "      <td>2.130133</td>\n",
       "      <td>-0.175567</td>\n",
       "      <td>0.654898</td>\n",
       "      <td>-0.608557</td>\n",
       "      <td>0.799079</td>\n",
       "      <td>-0.749562</td>\n",
       "      <td>-0.175757</td>\n",
       "      <td>0.959286</td>\n",
       "      <td>-0.903130</td>\n",
       "      <td>-0.175857</td>\n",
       "      <td>-0.721667</td>\n",
       "      <td>-0.309652</td>\n",
       "      <td>0.923445</td>\n",
       "      <td>-0.17681</td>\n",
       "      <td>-0.460679</td>\n",
       "      <td>-0.583435</td>\n",
       "      <td>-0.214282</td>\n",
       "      <td>-0.155731</td>\n",
       "      <td>-0.499161</td>\n",
       "      <td>-0.614078</td>\n",
       "      <td>5.676203</td>\n",
       "      <td>-0.583748</td>\n",
       "      <td>-0.214323</td>\n",
       "      <td>-0.460171</td>\n",
       "      <td>1.626968</td>\n",
       "      <td>-0.498759</td>\n",
       "      <td>-0.155333</td>\n",
       "      <td>-0.176509</td>\n",
       "      <td>4.658816</td>\n",
       "      <td>-0.155866</td>\n",
       "      <td>-0.582391</td>\n",
       "      <td>-0.459270</td>\n",
       "      <td>-0.615181</td>\n",
       "      <td>-0.499895</td>\n",
       "      <td>-0.176759</td>\n",
       "      <td>1.431019</td>\n",
       "      <td>-0.301501</td>\n",
       "      <td>-0.215507</td>\n",
       "      <td>-1.028728</td>\n",
       "      <td>-0.175948</td>\n",
       "      <td>-0.175794</td>\n",
       "      <td>-0.405564</td>\n",
       "      <td>-0.350332</td>\n",
       "      <td>-0.484009</td>\n",
       "      <td>-0.202636</td>\n",
       "      <td>2.104904</td>\n",
       "      <td>-0.439554</td>\n",
       "      <td>-0.410403</td>\n",
       "      <td>-0.175778</td>\n",
       "      <td>-0.308234</td>\n",
       "      <td>-0.26932</td>\n",
       "      <td>-0.36493</td>\n",
       "      <td>-0.157424</td>\n",
       "      <td>-0.360126</td>\n",
       "      <td>-0.334774</td>\n",
       "      <td>-0.312772</td>\n",
       "      <td>-0.390846</td>\n",
       "      <td>5.324435</td>\n",
       "      <td>-0.060459</td>\n",
       "      <td>-0.305435</td>\n",
       "      <td>-0.358131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.288591</td>\n",
       "      <td>-1.115063</td>\n",
       "      <td>-0.825919</td>\n",
       "      <td>0.912422</td>\n",
       "      <td>1.672695</td>\n",
       "      <td>-0.984019</td>\n",
       "      <td>-1.114748</td>\n",
       "      <td>1.726368</td>\n",
       "      <td>-1.319574</td>\n",
       "      <td>-1.275857</td>\n",
       "      <td>-1.575648</td>\n",
       "      <td>0</td>\n",
       "      <td>5.706372</td>\n",
       "      <td>-2.709989</td>\n",
       "      <td>-0.314583</td>\n",
       "      <td>-0.175987</td>\n",
       "      <td>0.516557</td>\n",
       "      <td>-0.469454</td>\n",
       "      <td>-0.175567</td>\n",
       "      <td>0.654898</td>\n",
       "      <td>-0.608557</td>\n",
       "      <td>0.799079</td>\n",
       "      <td>-0.749562</td>\n",
       "      <td>-0.175757</td>\n",
       "      <td>0.959286</td>\n",
       "      <td>-0.903130</td>\n",
       "      <td>-0.175857</td>\n",
       "      <td>-0.721667</td>\n",
       "      <td>-0.309652</td>\n",
       "      <td>0.923445</td>\n",
       "      <td>-0.17681</td>\n",
       "      <td>2.170707</td>\n",
       "      <td>-0.583435</td>\n",
       "      <td>-0.214282</td>\n",
       "      <td>-0.155731</td>\n",
       "      <td>-0.499161</td>\n",
       "      <td>-0.614078</td>\n",
       "      <td>-0.176174</td>\n",
       "      <td>-0.583748</td>\n",
       "      <td>-0.214323</td>\n",
       "      <td>-0.460171</td>\n",
       "      <td>1.626968</td>\n",
       "      <td>-0.498759</td>\n",
       "      <td>-0.155333</td>\n",
       "      <td>-0.176509</td>\n",
       "      <td>-0.214647</td>\n",
       "      <td>-0.155866</td>\n",
       "      <td>-0.582391</td>\n",
       "      <td>2.177366</td>\n",
       "      <td>-0.615181</td>\n",
       "      <td>-0.499895</td>\n",
       "      <td>-0.176759</td>\n",
       "      <td>-0.698803</td>\n",
       "      <td>-0.301501</td>\n",
       "      <td>-0.215507</td>\n",
       "      <td>0.972074</td>\n",
       "      <td>-0.175948</td>\n",
       "      <td>-0.175794</td>\n",
       "      <td>-0.405564</td>\n",
       "      <td>-0.350332</td>\n",
       "      <td>2.066077</td>\n",
       "      <td>-0.202636</td>\n",
       "      <td>-0.475081</td>\n",
       "      <td>-0.439554</td>\n",
       "      <td>-0.410403</td>\n",
       "      <td>-0.175778</td>\n",
       "      <td>-0.308234</td>\n",
       "      <td>-0.26932</td>\n",
       "      <td>2.74025</td>\n",
       "      <td>-0.157424</td>\n",
       "      <td>-0.360126</td>\n",
       "      <td>-0.334774</td>\n",
       "      <td>-0.312772</td>\n",
       "      <td>-0.390846</td>\n",
       "      <td>-0.187813</td>\n",
       "      <td>-0.060459</td>\n",
       "      <td>-0.305435</td>\n",
       "      <td>-0.358131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.071387</td>\n",
       "      <td>-0.845965</td>\n",
       "      <td>1.151736</td>\n",
       "      <td>-1.672856</td>\n",
       "      <td>1.030853</td>\n",
       "      <td>1.226857</td>\n",
       "      <td>1.606769</td>\n",
       "      <td>-0.568124</td>\n",
       "      <td>0.084412</td>\n",
       "      <td>-1.275857</td>\n",
       "      <td>-0.675529</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.175243</td>\n",
       "      <td>0.369005</td>\n",
       "      <td>-0.314583</td>\n",
       "      <td>5.682239</td>\n",
       "      <td>-1.935894</td>\n",
       "      <td>-0.469454</td>\n",
       "      <td>-0.175567</td>\n",
       "      <td>0.654898</td>\n",
       "      <td>-0.608557</td>\n",
       "      <td>-1.251440</td>\n",
       "      <td>1.334112</td>\n",
       "      <td>-0.175757</td>\n",
       "      <td>0.959286</td>\n",
       "      <td>-0.903130</td>\n",
       "      <td>-0.175857</td>\n",
       "      <td>-0.721667</td>\n",
       "      <td>-0.309652</td>\n",
       "      <td>0.923445</td>\n",
       "      <td>-0.17681</td>\n",
       "      <td>-0.460679</td>\n",
       "      <td>-0.583435</td>\n",
       "      <td>-0.214282</td>\n",
       "      <td>-0.155731</td>\n",
       "      <td>-0.499161</td>\n",
       "      <td>1.628458</td>\n",
       "      <td>-0.176174</td>\n",
       "      <td>-0.583748</td>\n",
       "      <td>-0.214323</td>\n",
       "      <td>-0.460171</td>\n",
       "      <td>1.626968</td>\n",
       "      <td>-0.498759</td>\n",
       "      <td>-0.155333</td>\n",
       "      <td>-0.176509</td>\n",
       "      <td>-0.214647</td>\n",
       "      <td>-0.155866</td>\n",
       "      <td>1.717059</td>\n",
       "      <td>-0.459270</td>\n",
       "      <td>-0.615181</td>\n",
       "      <td>-0.499895</td>\n",
       "      <td>-0.176759</td>\n",
       "      <td>-0.698803</td>\n",
       "      <td>-0.301501</td>\n",
       "      <td>-0.215507</td>\n",
       "      <td>-1.028728</td>\n",
       "      <td>5.683507</td>\n",
       "      <td>-0.175794</td>\n",
       "      <td>-0.405564</td>\n",
       "      <td>-0.350332</td>\n",
       "      <td>-0.484009</td>\n",
       "      <td>-0.202636</td>\n",
       "      <td>2.104904</td>\n",
       "      <td>-0.439554</td>\n",
       "      <td>-0.410403</td>\n",
       "      <td>-0.175778</td>\n",
       "      <td>-0.308234</td>\n",
       "      <td>-0.26932</td>\n",
       "      <td>-0.36493</td>\n",
       "      <td>-0.157424</td>\n",
       "      <td>-0.360126</td>\n",
       "      <td>-0.334774</td>\n",
       "      <td>-0.312772</td>\n",
       "      <td>-0.390846</td>\n",
       "      <td>-0.187813</td>\n",
       "      <td>-0.060459</td>\n",
       "      <td>-0.305435</td>\n",
       "      <td>2.792271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     nom_5     nom_6     nom_7     nom_8     nom_9     ord_0     ord_1  \\\n",
       "0   0  1.311572  0.616130 -0.282442 -1.642618 -1.597645  1.226857 -0.434369   \n",
       "1   1 -1.022687 -0.850450 -1.188238 -0.614555  1.588644  1.226857  1.606769   \n",
       "2   2  0.764437 -0.099220 -0.237152 -0.115642 -1.640435  1.226857 -1.795128   \n",
       "3   3 -0.288591 -1.115063 -0.825919  0.912422  1.672695 -0.984019 -1.114748   \n",
       "4   4 -0.071387 -0.845965  1.151736 -1.672856  1.030853  1.226857  1.606769   \n",
       "\n",
       "      ord_2     ord_3     ord_4     ord_5  target  bin_0_x0_-1.0  \\\n",
       "0  0.579122 -0.918435  1.038410 -0.569633       0      -0.175243   \n",
       "1  0.005499 -0.517297  1.424121  1.089410       0      -0.175243   \n",
       "2 -1.141747  1.287828  0.395558  0.295188       0      -0.175243   \n",
       "3  1.726368 -1.319574 -1.275857 -1.575648       0       5.706372   \n",
       "4 -0.568124  0.084412 -1.275857 -0.675529       0      -0.175243   \n",
       "\n",
       "   bin_0_x0_0.0  bin_0_x0_1.0  bin_1_x0_-1.0  bin_1_x0_0.0  bin_1_x0_1.0  \\\n",
       "0      0.369005     -0.314583      -0.175987      0.516557     -0.469454   \n",
       "1     -2.709989      3.178808      -0.175987     -1.935894      2.130133   \n",
       "2      0.369005     -0.314583      -0.175987     -1.935894      2.130133   \n",
       "3     -2.709989     -0.314583      -0.175987      0.516557     -0.469454   \n",
       "4      0.369005     -0.314583       5.682239     -1.935894     -0.469454   \n",
       "\n",
       "   bin_2_x0_-1.0  bin_2_x0_0.0  bin_2_x0_1.0  bin_3_x0_F  bin_3_x0_T  \\\n",
       "0      -0.175567      0.654898     -0.608557    0.799079   -0.749562   \n",
       "1      -0.175567      0.654898     -0.608557    0.799079   -0.749562   \n",
       "2      -0.175567      0.654898     -0.608557    0.799079   -0.749562   \n",
       "3      -0.175567      0.654898     -0.608557    0.799079   -0.749562   \n",
       "4      -0.175567      0.654898     -0.608557   -1.251440    1.334112   \n",
       "\n",
       "   bin_3_x0_missing  bin_4_x0_N  bin_4_x0_Y  bin_4_x0_missing  nom_0_x0_Blue  \\\n",
       "0         -0.175757    0.959286   -0.903130         -0.175857      -0.721667   \n",
       "1         -0.175757   -1.042442    1.107261         -0.175857      -0.721667   \n",
       "2         -0.175757    0.959286   -0.903130         -0.175857      -0.721667   \n",
       "3         -0.175757    0.959286   -0.903130         -0.175857      -0.721667   \n",
       "4         -0.175757    0.959286   -0.903130         -0.175857      -0.721667   \n",
       "\n",
       "   nom_0_x0_Green  nom_0_x0_Red  nom_0_x0_missing  nom_1_x0_Circle  \\\n",
       "0       -0.309652      0.923445          -0.17681        -0.460679   \n",
       "1       -0.309652      0.923445          -0.17681        -0.460679   \n",
       "2       -0.309652      0.923445          -0.17681        -0.460679   \n",
       "3       -0.309652      0.923445          -0.17681         2.170707   \n",
       "4       -0.309652      0.923445          -0.17681        -0.460679   \n",
       "\n",
       "   nom_1_x0_Polygon  nom_1_x0_Square  nom_1_x0_Star  nom_1_x0_Trapezoid  \\\n",
       "0         -0.583435        -0.214282      -0.155731            2.003362   \n",
       "1         -0.583435        -0.214282       6.421316           -0.499161   \n",
       "2         -0.583435        -0.214282      -0.155731           -0.499161   \n",
       "3         -0.583435        -0.214282      -0.155731           -0.499161   \n",
       "4         -0.583435        -0.214282      -0.155731           -0.499161   \n",
       "\n",
       "   nom_1_x0_Triangle  nom_1_x0_missing  nom_2_x0_Axolotl  nom_2_x0_Cat  \\\n",
       "0          -0.614078         -0.176174         -0.583748     -0.214323   \n",
       "1          -0.614078         -0.176174          1.713069     -0.214323   \n",
       "2          -0.614078          5.676203         -0.583748     -0.214323   \n",
       "3          -0.614078         -0.176174         -0.583748     -0.214323   \n",
       "4           1.628458         -0.176174         -0.583748     -0.214323   \n",
       "\n",
       "   nom_2_x0_Dog  nom_2_x0_Hamster  nom_2_x0_Lion  nom_2_x0_Snake  \\\n",
       "0     -0.460171          1.626968      -0.498759       -0.155333   \n",
       "1     -0.460171         -0.614640      -0.498759       -0.155333   \n",
       "2     -0.460171          1.626968      -0.498759       -0.155333   \n",
       "3     -0.460171          1.626968      -0.498759       -0.155333   \n",
       "4     -0.460171          1.626968      -0.498759       -0.155333   \n",
       "\n",
       "   nom_2_x0_missing  nom_3_x0_Canada  nom_3_x0_China  nom_3_x0_Costa Rica  \\\n",
       "0         -0.176509        -0.214647       -0.155866            -0.582391   \n",
       "1         -0.176509        -0.214647       -0.155866            -0.582391   \n",
       "2         -0.176509         4.658816       -0.155866            -0.582391   \n",
       "3         -0.176509        -0.214647       -0.155866            -0.582391   \n",
       "4         -0.176509        -0.214647       -0.155866             1.717059   \n",
       "\n",
       "   nom_3_x0_Finland  nom_3_x0_India  nom_3_x0_Russia  nom_3_x0_missing  \\\n",
       "0         -0.459270       -0.615181         2.000419         -0.176759   \n",
       "1         -0.459270       -0.615181        -0.499895          5.657435   \n",
       "2         -0.459270       -0.615181        -0.499895         -0.176759   \n",
       "3          2.177366       -0.615181        -0.499895         -0.176759   \n",
       "4         -0.459270       -0.615181        -0.499895         -0.176759   \n",
       "\n",
       "   nom_4_x0_Bassoon  nom_4_x0_Oboe  nom_4_x0_Piano  nom_4_x0_Theremin  \\\n",
       "0          1.431019      -0.301501       -0.215507          -1.028728   \n",
       "1         -0.698803      -0.301501       -0.215507           0.972074   \n",
       "2          1.431019      -0.301501       -0.215507          -1.028728   \n",
       "3         -0.698803      -0.301501       -0.215507           0.972074   \n",
       "4         -0.698803      -0.301501       -0.215507          -1.028728   \n",
       "\n",
       "   nom_4_x0_missing  day_x0_-1.0  day_x0_1.0  day_x0_2.0  day_x0_3.0  \\\n",
       "0         -0.175948    -0.175794   -0.405564   -0.350332   -0.484009   \n",
       "1         -0.175948    -0.175794   -0.405564   -0.350332   -0.484009   \n",
       "2         -0.175948    -0.175794   -0.405564   -0.350332   -0.484009   \n",
       "3         -0.175948    -0.175794   -0.405564   -0.350332    2.066077   \n",
       "4          5.683507    -0.175794   -0.405564   -0.350332   -0.484009   \n",
       "\n",
       "   day_x0_4.0  day_x0_5.0  day_x0_6.0  day_x0_7.0  month_x0_-1.0  \\\n",
       "0   -0.202636   -0.475081    2.275033   -0.410403      -0.175778   \n",
       "1   -0.202636   -0.475081   -0.439554    2.436631      -0.175778   \n",
       "2   -0.202636    2.104904   -0.439554   -0.410403      -0.175778   \n",
       "3   -0.202636   -0.475081   -0.439554   -0.410403      -0.175778   \n",
       "4   -0.202636    2.104904   -0.439554   -0.410403      -0.175778   \n",
       "\n",
       "   month_x0_1.0  month_x0_2.0  month_x0_3.0  month_x0_4.0  month_x0_5.0  \\\n",
       "0     -0.308234      -0.26932       2.74025     -0.157424     -0.360126   \n",
       "1     -0.308234      -0.26932      -0.36493     -0.157424     -0.360126   \n",
       "2     -0.308234      -0.26932      -0.36493     -0.157424     -0.360126   \n",
       "3     -0.308234      -0.26932       2.74025     -0.157424     -0.360126   \n",
       "4     -0.308234      -0.26932      -0.36493     -0.157424     -0.360126   \n",
       "\n",
       "   month_x0_6.0  month_x0_7.0  month_x0_8.0  month_x0_9.0  month_x0_10.0  \\\n",
       "0     -0.334774     -0.312772     -0.390846     -0.187813      -0.060459   \n",
       "1     -0.334774      3.197219     -0.390846     -0.187813      -0.060459   \n",
       "2     -0.334774     -0.312772     -0.390846      5.324435      -0.060459   \n",
       "3     -0.334774     -0.312772     -0.390846     -0.187813      -0.060459   \n",
       "4     -0.334774     -0.312772     -0.390846     -0.187813      -0.060459   \n",
       "\n",
       "   month_x0_11.0  month_x0_12.0  \n",
       "0      -0.305435      -0.358131  \n",
       "1      -0.305435      -0.358131  \n",
       "2      -0.305435      -0.358131  \n",
       "3      -0.305435      -0.358131  \n",
       "4      -0.305435       2.792271  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.target != -1].reset_index(drop=True).loc[:, features].values\n",
    "test = data[data.target == -1].reset_index(drop=True).loc[:, features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /brain/engine/.cache/poetry/engine-py3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(len(features),))\n",
    "\n",
    "x = layers.Dense(100, activation=\"relu\")(inputs)\n",
    "\n",
    "x = layers.Dense(20, activation=\"linear\", name='encoded')(x)\n",
    "\n",
    "x = layers.Dense(100, activation=\"relu\")(x)\n",
    "\n",
    "y = layers.Dense(len(features), activation=\"linear\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=y)\n",
    "\n",
    "layer_name = 'encoded'\n",
    "encoder = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900000 samples, validate on 100000 samples\n",
      "Epoch 1/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.4852 - mean_squared_error: 0.4852 - val_loss: 0.3326 - val_mean_squared_error: 0.3326\n",
      "Epoch 2/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.2857 - mean_squared_error: 0.2857 - val_loss: 0.2425 - val_mean_squared_error: 0.2425\n",
      "Epoch 3/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.2165 - mean_squared_error: 0.2165 - val_loss: 0.1973 - val_mean_squared_error: 0.1973\n",
      "Epoch 4/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1835 - mean_squared_error: 0.1835 - val_loss: 0.1721 - val_mean_squared_error: 0.1721\n",
      "Epoch 5/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1668 - mean_squared_error: 0.1668 - val_loss: 0.1628 - val_mean_squared_error: 0.1628\n",
      "Epoch 6/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1599 - mean_squared_error: 0.1599 - val_loss: 0.1567 - val_mean_squared_error: 0.1567\n",
      "Epoch 7/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1528 - mean_squared_error: 0.1528 - val_loss: 0.1492 - val_mean_squared_error: 0.1492\n",
      "Epoch 8/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1469 - mean_squared_error: 0.1469 - val_loss: 0.1447 - val_mean_squared_error: 0.1447\n",
      "Epoch 9/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1435 - mean_squared_error: 0.1435 - val_loss: 0.1420 - val_mean_squared_error: 0.1420\n",
      "Epoch 10/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1412 - mean_squared_error: 0.1412 - val_loss: 0.1398 - val_mean_squared_error: 0.1398\n",
      "Epoch 11/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1394 - mean_squared_error: 0.1394 - val_loss: 0.1386 - val_mean_squared_error: 0.1386\n",
      "Epoch 12/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1380 - mean_squared_error: 0.1380 - val_loss: 0.1371 - val_mean_squared_error: 0.1371\n",
      "Epoch 13/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1368 - mean_squared_error: 0.1368 - val_loss: 0.1359 - val_mean_squared_error: 0.1359\n",
      "Epoch 14/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1357 - mean_squared_error: 0.1357 - val_loss: 0.1353 - val_mean_squared_error: 0.1353\n",
      "Epoch 15/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1348 - mean_squared_error: 0.1348 - val_loss: 0.1342 - val_mean_squared_error: 0.1342\n",
      "Epoch 16/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1340 - mean_squared_error: 0.1340 - val_loss: 0.1337 - val_mean_squared_error: 0.1337\n",
      "Epoch 17/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1333 - mean_squared_error: 0.1333 - val_loss: 0.1327 - val_mean_squared_error: 0.1327\n",
      "Epoch 18/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1326 - mean_squared_error: 0.1326 - val_loss: 0.1322 - val_mean_squared_error: 0.1322\n",
      "Epoch 19/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1321 - mean_squared_error: 0.1321 - val_loss: 0.1314 - val_mean_squared_error: 0.1314\n",
      "Epoch 20/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1315 - mean_squared_error: 0.1315 - val_loss: 0.1308 - val_mean_squared_error: 0.1308\n",
      "Epoch 21/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1310 - mean_squared_error: 0.1310 - val_loss: 0.1305 - val_mean_squared_error: 0.1305\n",
      "Epoch 22/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1305 - mean_squared_error: 0.1305 - val_loss: 0.1306 - val_mean_squared_error: 0.1306\n",
      "Epoch 23/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1301 - mean_squared_error: 0.1301 - val_loss: 0.1296 - val_mean_squared_error: 0.1296\n",
      "Epoch 24/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1296 - mean_squared_error: 0.1296 - val_loss: 0.1293 - val_mean_squared_error: 0.1293\n",
      "Epoch 25/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1291 - mean_squared_error: 0.1291 - val_loss: 0.1283 - val_mean_squared_error: 0.1283\n",
      "Epoch 26/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1281 - mean_squared_error: 0.1281 - val_loss: 0.1271 - val_mean_squared_error: 0.1271\n",
      "Epoch 27/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1257 - mean_squared_error: 0.1257 - val_loss: 0.1235 - val_mean_squared_error: 0.1235\n",
      "Epoch 28/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1219 - mean_squared_error: 0.1219 - val_loss: 0.1199 - val_mean_squared_error: 0.1199\n",
      "Epoch 29/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1194 - mean_squared_error: 0.1194 - val_loss: 0.1185 - val_mean_squared_error: 0.1185\n",
      "Epoch 30/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1181 - mean_squared_error: 0.1181 - val_loss: 0.1172 - val_mean_squared_error: 0.1172\n",
      "Epoch 31/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1173 - mean_squared_error: 0.1173 - val_loss: 0.1170 - val_mean_squared_error: 0.1170\n",
      "Epoch 32/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1168 - mean_squared_error: 0.1168 - val_loss: 0.1167 - val_mean_squared_error: 0.1167\n",
      "Epoch 33/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1165 - mean_squared_error: 0.1165 - val_loss: 0.1165 - val_mean_squared_error: 0.1165\n",
      "Epoch 34/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1162 - mean_squared_error: 0.1162 - val_loss: 0.1158 - val_mean_squared_error: 0.1158\n",
      "Epoch 35/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1159 - mean_squared_error: 0.1159 - val_loss: 0.1160 - val_mean_squared_error: 0.1160\n",
      "Epoch 36/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1157 - mean_squared_error: 0.1157 - val_loss: 0.1150 - val_mean_squared_error: 0.1150\n",
      "Epoch 37/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1154 - mean_squared_error: 0.1154 - val_loss: 0.1148 - val_mean_squared_error: 0.1148\n",
      "Epoch 38/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1152 - mean_squared_error: 0.1152 - val_loss: 0.1148 - val_mean_squared_error: 0.1148\n",
      "Epoch 39/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1149 - mean_squared_error: 0.1149 - val_loss: 0.1147 - val_mean_squared_error: 0.1147\n",
      "Epoch 40/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1147 - mean_squared_error: 0.1147 - val_loss: 0.1143 - val_mean_squared_error: 0.1143\n",
      "Epoch 41/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1145 - mean_squared_error: 0.1145 - val_loss: 0.1143 - val_mean_squared_error: 0.1143\n",
      "Epoch 42/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1143 - mean_squared_error: 0.1143 - val_loss: 0.1137 - val_mean_squared_error: 0.1137\n",
      "Epoch 43/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1141 - mean_squared_error: 0.1141 - val_loss: 0.1136 - val_mean_squared_error: 0.1136\n",
      "Epoch 44/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1140 - mean_squared_error: 0.1140 - val_loss: 0.1136 - val_mean_squared_error: 0.1136\n",
      "Epoch 45/100\n",
      "881664/900000 [============================>.] - ETA: 0s - loss: 0.1139 - mean_squared_error: 0.1139\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1139 - mean_squared_error: 0.1139 - val_loss: 0.1139 - val_mean_squared_error: 0.1139\n",
      "Epoch 46/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1128 - mean_squared_error: 0.1128 - val_loss: 0.1127 - val_mean_squared_error: 0.1127\n",
      "Epoch 47/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1128 - mean_squared_error: 0.1128 - val_loss: 0.1126 - val_mean_squared_error: 0.1126\n",
      "Epoch 48/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1128 - mean_squared_error: 0.1128 - val_loss: 0.1126 - val_mean_squared_error: 0.1126\n",
      "Epoch 49/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1127 - mean_squared_error: 0.1127 - val_loss: 0.1123 - val_mean_squared_error: 0.1123\n",
      "Epoch 50/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1126 - mean_squared_error: 0.1126 - val_loss: 0.1125 - val_mean_squared_error: 0.1125\n",
      "Epoch 51/100\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1125 - mean_squared_error: 0.1125 - val_loss: 0.1122 - val_mean_squared_error: 0.1122\n",
      "Epoch 52/100\n",
      "880640/900000 [============================>.] - ETA: 0s - loss: 0.1124 - mean_squared_error: 0.1124Restoring model weights from the end of the best epoch.\n",
      "900000/900000 [==============================] - 2s 2us/sample - loss: 0.1124 - mean_squared_error: 0.1124 - val_loss: 0.1122 - val_mean_squared_error: 0.1122\n",
      "Epoch 00052: early stopping\n",
      "CPU times: user 5min 49s, sys: 40.7 s, total: 6min 29s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = data.loc[:, features].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(data, test_size=0.10, random_state=42)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor='val_mean_squared_error', min_delta=0.001, patience=5,\n",
    "                             verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor='val_mean_squared_error', factor=0.5,\n",
    "                                  patience=3, min_lr=1e-6, mode='min', verbose=1)\n",
    "\n",
    "model.fit(X_train,\n",
    "          X_train,\n",
    "          validation_data=(X_test, X_test),\n",
    "          verbose=1,\n",
    "          batch_size=1024,\n",
    "          callbacks=[es, rlr],\n",
    "          epochs=100\n",
    "         )\n",
    "\n",
    "test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6169328 , -0.2866975 ,  0.9114652 , -0.0864603 ,  0.3102562 ,\n",
       "       -0.30266073, -0.3026658 ,  0.23149244, -0.12209244,  0.11587837,\n",
       "        0.31851727, -0.17507222,  0.46805716, -0.44409624, -0.18371047,\n",
       "        0.51616234, -0.48290092, -0.16576144, -1.3495262 ,  1.4631467 ,\n",
       "       -1.3502947 ,  1.4105562 , -0.14125492, -1.0905625 ,  1.1601479 ,\n",
       "       -0.1915737 , -0.62457615, -0.3253173 ,  0.7989827 , -0.18966049,\n",
       "       -0.40072036, -0.406928  , -0.19405457, -0.17696643,  1.9928397 ,\n",
       "       -0.82404816, -0.16235083,  1.0171858 , -0.18207306,  0.3013304 ,\n",
       "       -0.8891585 , -0.13391063, -0.1588852 , -0.19687621, -0.26125297,\n",
       "        6.380669  , -0.59423095, -0.45748317, -0.61435306, -0.45500365,\n",
       "       -0.18785888, -0.760279  , -0.36884233, -0.25070715,  1.1079426 ,\n",
       "       -0.20316422, -0.16385056, -0.39958584, -0.32305723, -0.35398334,\n",
       "       -0.14247933, -0.3846414 , -0.47316778,  2.181378  , -0.1579098 ,\n",
       "       -0.29717654, -0.28540555, -0.33983368, -0.25159714, -0.3554234 ,\n",
       "       -0.3500367 , -0.31729704, -0.39539692, -0.14339106, -0.08726891,\n",
       "       -0.40144417,  2.8650997 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.73498277,  1.38081453,  1.10644605, -1.40072116, -0.6211279 ,\n",
       "        1.22685677,  0.24601018, -1.14174709, -0.9184353 ,  1.03840976,\n",
       "       -0.37548925, -0.1752427 ,  0.36900516, -0.31458336, -0.17598697,\n",
       "        0.5165573 , -0.46945426, -0.17556677, -1.52695442,  1.64323129,\n",
       "       -1.25144029,  1.33411204, -0.17575733, -1.04244188,  1.1072607 ,\n",
       "       -0.17585707, -0.7216674 , -0.30965207,  0.92344506, -0.17680969,\n",
       "       -0.46067943, -0.58343494, -0.21428204, -0.15573132,  2.00336246,\n",
       "       -0.61407801, -0.17617411,  1.71306942, -0.21432288, -0.46017057,\n",
       "       -0.61464008, -0.49875907, -0.1553334 , -0.17650872, -0.2146468 ,\n",
       "        6.41576737, -0.58239102, -0.45927047, -0.61518058, -0.49989531,\n",
       "       -0.17675856, -0.69880296, -0.30150082, -0.21550695,  0.97207378,\n",
       "       -0.1759477 , -0.1757936 , -0.40556369, -0.35033219, -0.48400895,\n",
       "       -0.2026365 , -0.47508104, -0.43955407,  2.43663088, -0.17577849,\n",
       "       -0.30823433, -0.26932003, -0.36493014, -0.15742398, -0.36012603,\n",
       "       -0.33477406, -0.31277179, -0.39084568, -0.18781334, -0.06045918,\n",
       "       -0.3054349 ,  2.79227091])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MSE=0.11258384567243777\n",
      "Random MSE=0.9996229299549075\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall MSE={}\".format(metrics.mean_squared_error(X_test, test_preds)))\n",
    "print(\"Random MSE={}\".format(metrics.mean_squared_error(X_test,\n",
    "                                                        np.zeros(shape=(X_test.shape[0], X_test.shape[1])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11258384567243777"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.11258384567243777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_train = encoder.predict(train)\n",
    "encode_test = encoder.predict(test)\n",
    "\n",
    "encode_train = pd.DataFrame(encode_train, columns=[f'enc_{i}' for i in range(encode_train.shape[1])])\n",
    "encode_test = pd.DataFrame(encode_test, columns=[f'enc_{i}' for i in range(encode_test.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_0</th>\n",
       "      <th>enc_1</th>\n",
       "      <th>enc_2</th>\n",
       "      <th>enc_3</th>\n",
       "      <th>enc_4</th>\n",
       "      <th>enc_5</th>\n",
       "      <th>enc_6</th>\n",
       "      <th>enc_7</th>\n",
       "      <th>enc_8</th>\n",
       "      <th>enc_9</th>\n",
       "      <th>enc_10</th>\n",
       "      <th>enc_11</th>\n",
       "      <th>enc_12</th>\n",
       "      <th>enc_13</th>\n",
       "      <th>enc_14</th>\n",
       "      <th>enc_15</th>\n",
       "      <th>enc_16</th>\n",
       "      <th>enc_17</th>\n",
       "      <th>enc_18</th>\n",
       "      <th>enc_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-3.628197</td>\n",
       "      <td>-4.214615</td>\n",
       "      <td>3.162791</td>\n",
       "      <td>-2.851017</td>\n",
       "      <td>0.733684</td>\n",
       "      <td>-2.105170</td>\n",
       "      <td>-3.654043</td>\n",
       "      <td>3.368169</td>\n",
       "      <td>8.733227</td>\n",
       "      <td>-9.304165</td>\n",
       "      <td>-6.155349</td>\n",
       "      <td>-13.961720</td>\n",
       "      <td>-1.860988</td>\n",
       "      <td>3.261696</td>\n",
       "      <td>-2.552499</td>\n",
       "      <td>-7.462784</td>\n",
       "      <td>-6.648254</td>\n",
       "      <td>1.215031</td>\n",
       "      <td>3.039558</td>\n",
       "      <td>-7.457930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.473229</td>\n",
       "      <td>-12.043126</td>\n",
       "      <td>-3.110718</td>\n",
       "      <td>-7.116550</td>\n",
       "      <td>0.137809</td>\n",
       "      <td>0.137545</td>\n",
       "      <td>0.894782</td>\n",
       "      <td>-1.195416</td>\n",
       "      <td>0.025465</td>\n",
       "      <td>-9.848320</td>\n",
       "      <td>-3.185985</td>\n",
       "      <td>-2.082869</td>\n",
       "      <td>1.452042</td>\n",
       "      <td>1.212522</td>\n",
       "      <td>-2.001684</td>\n",
       "      <td>1.752465</td>\n",
       "      <td>-6.622913</td>\n",
       "      <td>-4.465862</td>\n",
       "      <td>1.056876</td>\n",
       "      <td>-2.896130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-4.723306</td>\n",
       "      <td>-9.212559</td>\n",
       "      <td>6.908667</td>\n",
       "      <td>-5.521707</td>\n",
       "      <td>-1.525551</td>\n",
       "      <td>-4.305672</td>\n",
       "      <td>-9.828537</td>\n",
       "      <td>-2.415355</td>\n",
       "      <td>7.607178</td>\n",
       "      <td>-13.408950</td>\n",
       "      <td>2.264282</td>\n",
       "      <td>-14.757087</td>\n",
       "      <td>1.142129</td>\n",
       "      <td>2.798655</td>\n",
       "      <td>2.902924</td>\n",
       "      <td>-7.999272</td>\n",
       "      <td>-5.391744</td>\n",
       "      <td>0.190947</td>\n",
       "      <td>-16.148094</td>\n",
       "      <td>-1.135958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.615331</td>\n",
       "      <td>-11.242261</td>\n",
       "      <td>7.183455</td>\n",
       "      <td>-5.536698</td>\n",
       "      <td>8.040099</td>\n",
       "      <td>-1.410003</td>\n",
       "      <td>-8.376881</td>\n",
       "      <td>-4.480841</td>\n",
       "      <td>1.970797</td>\n",
       "      <td>-9.971006</td>\n",
       "      <td>-12.468792</td>\n",
       "      <td>-6.622226</td>\n",
       "      <td>5.265586</td>\n",
       "      <td>-0.054815</td>\n",
       "      <td>-0.782956</td>\n",
       "      <td>-1.878253</td>\n",
       "      <td>-2.096591</td>\n",
       "      <td>1.068002</td>\n",
       "      <td>2.522064</td>\n",
       "      <td>-1.252572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.041569</td>\n",
       "      <td>1.142792</td>\n",
       "      <td>6.858114</td>\n",
       "      <td>-1.561865</td>\n",
       "      <td>-4.468106</td>\n",
       "      <td>-2.491810</td>\n",
       "      <td>-5.631959</td>\n",
       "      <td>3.342344</td>\n",
       "      <td>2.752319</td>\n",
       "      <td>-14.936157</td>\n",
       "      <td>-5.771559</td>\n",
       "      <td>-10.802589</td>\n",
       "      <td>-0.177584</td>\n",
       "      <td>6.790238</td>\n",
       "      <td>4.165288</td>\n",
       "      <td>-2.998211</td>\n",
       "      <td>-1.888003</td>\n",
       "      <td>3.092746</td>\n",
       "      <td>4.096474</td>\n",
       "      <td>-8.714581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      enc_0      enc_1     enc_2     enc_3     enc_4     enc_5     enc_6  \\\n",
       "0 -3.628197  -4.214615  3.162791 -2.851017  0.733684 -2.105170 -3.654043   \n",
       "1  5.473229 -12.043126 -3.110718 -7.116550  0.137809  0.137545  0.894782   \n",
       "2 -4.723306  -9.212559  6.908667 -5.521707 -1.525551 -4.305672 -9.828537   \n",
       "3 -0.615331 -11.242261  7.183455 -5.536698  8.040099 -1.410003 -8.376881   \n",
       "4  1.041569   1.142792  6.858114 -1.561865 -4.468106 -2.491810 -5.631959   \n",
       "\n",
       "      enc_7     enc_8      enc_9     enc_10     enc_11    enc_12    enc_13  \\\n",
       "0  3.368169  8.733227  -9.304165  -6.155349 -13.961720 -1.860988  3.261696   \n",
       "1 -1.195416  0.025465  -9.848320  -3.185985  -2.082869  1.452042  1.212522   \n",
       "2 -2.415355  7.607178 -13.408950   2.264282 -14.757087  1.142129  2.798655   \n",
       "3 -4.480841  1.970797  -9.971006 -12.468792  -6.622226  5.265586 -0.054815   \n",
       "4  3.342344  2.752319 -14.936157  -5.771559 -10.802589 -0.177584  6.790238   \n",
       "\n",
       "     enc_14    enc_15    enc_16    enc_17     enc_18    enc_19  \n",
       "0 -2.552499 -7.462784 -6.648254  1.215031   3.039558 -7.457930  \n",
       "1 -2.001684  1.752465 -6.622913 -4.465862   1.056876 -2.896130  \n",
       "2  2.902924 -7.999272 -5.391744  0.190947 -16.148094 -1.135958  \n",
       "3 -0.782956 -1.878253 -2.096591  1.068002   2.522064 -1.252572  \n",
       "4  4.165288 -2.998211 -1.888003  3.092746   4.096474 -8.714581  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_0</th>\n",
       "      <th>enc_1</th>\n",
       "      <th>enc_2</th>\n",
       "      <th>enc_3</th>\n",
       "      <th>enc_4</th>\n",
       "      <th>enc_5</th>\n",
       "      <th>enc_6</th>\n",
       "      <th>enc_7</th>\n",
       "      <th>enc_8</th>\n",
       "      <th>enc_9</th>\n",
       "      <th>enc_10</th>\n",
       "      <th>enc_11</th>\n",
       "      <th>enc_12</th>\n",
       "      <th>enc_13</th>\n",
       "      <th>enc_14</th>\n",
       "      <th>enc_15</th>\n",
       "      <th>enc_16</th>\n",
       "      <th>enc_17</th>\n",
       "      <th>enc_18</th>\n",
       "      <th>enc_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.601917</td>\n",
       "      <td>-6.748988</td>\n",
       "      <td>-0.873609</td>\n",
       "      <td>-10.028065</td>\n",
       "      <td>-0.826670</td>\n",
       "      <td>-2.201148</td>\n",
       "      <td>-0.071471</td>\n",
       "      <td>0.754162</td>\n",
       "      <td>6.668080</td>\n",
       "      <td>-12.246215</td>\n",
       "      <td>4.091609</td>\n",
       "      <td>-2.580008</td>\n",
       "      <td>-2.345709</td>\n",
       "      <td>5.427414</td>\n",
       "      <td>0.998928</td>\n",
       "      <td>-1.292549</td>\n",
       "      <td>-5.212106</td>\n",
       "      <td>-5.284838</td>\n",
       "      <td>1.957668</td>\n",
       "      <td>2.370052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.278443</td>\n",
       "      <td>-2.701591</td>\n",
       "      <td>5.499518</td>\n",
       "      <td>-1.492787</td>\n",
       "      <td>1.074574</td>\n",
       "      <td>0.608068</td>\n",
       "      <td>-5.391108</td>\n",
       "      <td>4.827563</td>\n",
       "      <td>2.817517</td>\n",
       "      <td>-11.315014</td>\n",
       "      <td>3.631675</td>\n",
       "      <td>-9.750927</td>\n",
       "      <td>-0.588090</td>\n",
       "      <td>1.555272</td>\n",
       "      <td>9.241634</td>\n",
       "      <td>-4.863257</td>\n",
       "      <td>-3.699225</td>\n",
       "      <td>1.486904</td>\n",
       "      <td>7.172283</td>\n",
       "      <td>-6.245288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.124808</td>\n",
       "      <td>-6.116314</td>\n",
       "      <td>2.509565</td>\n",
       "      <td>-4.807785</td>\n",
       "      <td>-2.905211</td>\n",
       "      <td>2.361596</td>\n",
       "      <td>-0.425926</td>\n",
       "      <td>6.399082</td>\n",
       "      <td>0.469024</td>\n",
       "      <td>-12.790155</td>\n",
       "      <td>5.471367</td>\n",
       "      <td>-4.353714</td>\n",
       "      <td>-1.568642</td>\n",
       "      <td>0.223909</td>\n",
       "      <td>8.715662</td>\n",
       "      <td>-4.585989</td>\n",
       "      <td>-3.442437</td>\n",
       "      <td>0.423855</td>\n",
       "      <td>6.123113</td>\n",
       "      <td>-4.636481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.536647</td>\n",
       "      <td>-7.661001</td>\n",
       "      <td>3.603499</td>\n",
       "      <td>-6.089979</td>\n",
       "      <td>-2.297252</td>\n",
       "      <td>-2.953677</td>\n",
       "      <td>-1.661912</td>\n",
       "      <td>8.359610</td>\n",
       "      <td>-0.131453</td>\n",
       "      <td>-10.906069</td>\n",
       "      <td>-0.797260</td>\n",
       "      <td>0.944871</td>\n",
       "      <td>5.838966</td>\n",
       "      <td>-0.948586</td>\n",
       "      <td>6.635248</td>\n",
       "      <td>-2.916905</td>\n",
       "      <td>-1.529340</td>\n",
       "      <td>-0.501608</td>\n",
       "      <td>7.456985</td>\n",
       "      <td>1.407279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.167632</td>\n",
       "      <td>-10.014113</td>\n",
       "      <td>-4.307736</td>\n",
       "      <td>-0.614916</td>\n",
       "      <td>6.423235</td>\n",
       "      <td>4.479852</td>\n",
       "      <td>-2.872722</td>\n",
       "      <td>4.649438</td>\n",
       "      <td>8.898916</td>\n",
       "      <td>-13.349398</td>\n",
       "      <td>1.766877</td>\n",
       "      <td>-8.594969</td>\n",
       "      <td>-0.846956</td>\n",
       "      <td>4.281952</td>\n",
       "      <td>-6.167549</td>\n",
       "      <td>2.251335</td>\n",
       "      <td>-5.337626</td>\n",
       "      <td>-1.727542</td>\n",
       "      <td>-1.617362</td>\n",
       "      <td>-0.052094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      enc_0      enc_1     enc_2      enc_3     enc_4     enc_5     enc_6  \\\n",
       "0 -1.601917  -6.748988 -0.873609 -10.028065 -0.826670 -2.201148 -0.071471   \n",
       "1 -0.278443  -2.701591  5.499518  -1.492787  1.074574  0.608068 -5.391108   \n",
       "2 -0.124808  -6.116314  2.509565  -4.807785 -2.905211  2.361596 -0.425926   \n",
       "3  4.536647  -7.661001  3.603499  -6.089979 -2.297252 -2.953677 -1.661912   \n",
       "4  0.167632 -10.014113 -4.307736  -0.614916  6.423235  4.479852 -2.872722   \n",
       "\n",
       "      enc_7     enc_8      enc_9    enc_10    enc_11    enc_12    enc_13  \\\n",
       "0  0.754162  6.668080 -12.246215  4.091609 -2.580008 -2.345709  5.427414   \n",
       "1  4.827563  2.817517 -11.315014  3.631675 -9.750927 -0.588090  1.555272   \n",
       "2  6.399082  0.469024 -12.790155  5.471367 -4.353714 -1.568642  0.223909   \n",
       "3  8.359610 -0.131453 -10.906069 -0.797260  0.944871  5.838966 -0.948586   \n",
       "4  4.649438  8.898916 -13.349398  1.766877 -8.594969 -0.846956  4.281952   \n",
       "\n",
       "     enc_14    enc_15    enc_16    enc_17    enc_18    enc_19  \n",
       "0  0.998928 -1.292549 -5.212106 -5.284838  1.957668  2.370052  \n",
       "1  9.241634 -4.863257 -3.699225  1.486904  7.172283 -6.245288  \n",
       "2  8.715662 -4.585989 -3.442437  0.423855  6.123113 -4.636481  \n",
       "3  6.635248 -2.916905 -1.529340 -0.501608  7.456985  1.407279  \n",
       "4 -6.167549  2.251335 -5.337626 -1.727542 -1.617362 -0.052094  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_train.to_csv(\"cat_in_dat/train_autoencoder_ohe_20.csv\", index=False)\n",
    "encode_test.to_csv(\"cat_in_dat/test_autoencoder_ohe_20.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds /= 50\n",
    "test_ids = test.id.values\n",
    "print(\"Saving submission file\")\n",
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': test_ids,\n",
    "    'target': test_preds\n",
    "})\n",
    "submission.to_csv(\"cat_in_dat/submission_embeddings.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
