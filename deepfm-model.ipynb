{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This kernel uses Deepfm model from deepctr package**\n",
    "\n",
    "**Deepfm :** [Deepfm using deepctr](https://deepctr-doc.readthedocs.io/en/v0.6.3/deepctr.models.deepfm.html)\n",
    "\n",
    "Guo H, Tang R, Ye Y, et al. Deepfm: a factorization-machine based neural network for ctr prediction[J]. arXiv preprint arXiv:1703.04247, 2017.(https://arxiv.org/abs/1703.04247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --no-warn-conflicts -q deepctr\n",
    "!pip install --no-warn-conflicts -U -q scikit-learn==0.22.1\n",
    "!pip install category_encoders==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer, IterativeImputer, KNNImputer\n",
    "from category_encoders.cat_boost import CatBoostEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from deepctr.inputs import  SparseFeat, DenseFeat, get_feature_names\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import utils\n",
    "from deepctr.models import DeepFM\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cat_in_dat/train.csv')\n",
    "test = pd.read_csv('cat_in_dat/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"target\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_numeric(df):\n",
    "    \n",
    "    bin_3_mapping = {'T':1 , 'F':0}\n",
    "    bin_4_mapping = {'Y':1 , 'N':0}\n",
    "    nom_0_mapping = {'Red' : 0, 'Blue' : 1, 'Green' : 2}\n",
    "    nom_1_mapping = {'Trapezoid' : 0, 'Star' : 1, 'Circle': 2, 'Triangle' : 3, 'Polygon' : 4}\n",
    "    nom_2_mapping = {'Hamster' : 0 , 'Axolotl' : 1, 'Lion' : 2, 'Dog' : 3, 'Cat' : 4, 'Snake' : 5}\n",
    "    nom_3_mapping = {'Russia' : 0, 'Canada' : 1, 'Finland' : 2, 'Costa Rica' : 3, 'China' : 4, 'India' : 5}\n",
    "    nom_4_mapping = {'Bassoon' : 0, 'Theremin' : 1, 'Oboe' : 2, 'Piano' : 3}\n",
    "    nom_5_mapping = dict(zip((df.nom_5.dropna().unique()), range(len((df.nom_5.dropna().unique())))))\n",
    "    nom_6_mapping = dict(zip((df.nom_6.dropna().unique()), range(len((df.nom_6.dropna().unique())))))\n",
    "    nom_7_mapping = dict(zip((df.nom_7.dropna().unique()), range(len((df.nom_7.dropna().unique())))))\n",
    "    nom_8_mapping = dict(zip((df.nom_8.dropna().unique()), range(len((df.nom_8.dropna().unique())))))\n",
    "    nom_9_mapping = dict(zip((df.nom_9.dropna().unique()), range(len((df.nom_9.dropna().unique())))))\n",
    "    ord_1_mapping = {'Novice' : 0, 'Contributor' : 1, 'Expert' : 2, 'Master': 3, 'Grandmaster': 4}\n",
    "    ord_2_mapping = { 'Freezing': 0, 'Cold': 1, 'Warm' : 2, 'Hot': 3, 'Boiling Hot' : 4, 'Lava Hot' : 5}\n",
    "    ord_3_mapping = {'a':0, 'b':1, 'c':2 ,'d':3 ,'e':4, 'f':5, 'g':6, 'h':7, 'i':8, 'j':9, 'k':10, 'l':11, 'm':12, 'n':13, 'o':14}\n",
    "    ord_4_mapping = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'H':7, 'I':8, 'J':9, 'K':10,'L':11,'M':12,\n",
    "                 'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,'Z':25}\n",
    "    sorted_ord_5 = sorted(df.ord_5.dropna().unique())\n",
    "    ord_5_mapping = dict(zip(sorted_ord_5, range(len(sorted_ord_5))))\n",
    "\n",
    "    df['bin_3'] = df.loc[df.bin_3.notnull(), 'bin_3'].map(bin_3_mapping)\n",
    "    df['bin_4'] = df.loc[df.bin_4.notnull(), 'bin_4'].map(bin_4_mapping)\n",
    "    df['nom_0'] = df.loc[df.nom_0.notnull(), 'nom_0'].map(nom_0_mapping)\n",
    "    df['nom_1'] = df.loc[df.nom_1.notnull(), 'nom_1'].map(nom_1_mapping)\n",
    "    df['nom_2'] = df.loc[df.nom_2.notnull(), 'nom_2'].map(nom_2_mapping)\n",
    "    df['nom_3'] = df.loc[df.nom_3.notnull(), 'nom_3'].map(nom_3_mapping)\n",
    "    df['nom_4'] = df.loc[df.nom_4.notnull(), 'nom_4'].map(nom_4_mapping)\n",
    "    df['nom_5'] = df.loc[df.nom_5.notnull(), 'nom_5'].map(nom_5_mapping)\n",
    "    df['nom_6'] = df.loc[df.nom_6.notnull(), 'nom_6'].map(nom_6_mapping)\n",
    "    df['nom_7'] = df.loc[df.nom_7.notnull(), 'nom_7'].map(nom_7_mapping)\n",
    "    df['nom_8'] = df.loc[df.nom_8.notnull(), 'nom_8'].map(nom_8_mapping)\n",
    "    df['nom_9'] = df.loc[df.nom_9.notnull(), 'nom_9'].map(nom_9_mapping)\n",
    "    df['ord_1'] = df.loc[df.ord_1.notnull(), 'ord_1'].map(ord_1_mapping)\n",
    "    df['ord_2'] = df.loc[df.ord_2.notnull(), 'ord_2'].map(ord_2_mapping)\n",
    "    df['ord_3'] = df.loc[df.ord_3.notnull(), 'ord_3'].map(ord_3_mapping)\n",
    "    df['ord_4'] = df.loc[df.ord_4.notnull(), 'ord_4'].map(ord_4_mapping)\n",
    "    df['ord_5'] = df.loc[df.ord_5.notnull(), 'ord_5'].map(ord_5_mapping)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [feat for feat in train.columns if feat not in ['id','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sparse_features:\n",
    "    train_unique_values = set(train[col].dropna().unique())\n",
    "    test_unique_values  = set(test[col].dropna().unique())\n",
    "\n",
    "    symmetric_difference_values = train_unique_values.symmetric_difference(test_unique_values)\n",
    "    if symmetric_difference_values:\n",
    "        print(f'{len(symmetric_difference_values)} values in {col}, {symmetric_difference_values} Replaced with nan')\n",
    "        data.loc[data[col].isin(symmetric_difference_values), col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "features = [feat for feat in data.columns if feat not in ['target','id']]\n",
    "data[features] = convert_data_to_numeric(data[features])\n",
    "data[features] = data[features].astype('category')\n",
    "imp = IterativeImputer(max_iter=500, initial_strategy='most_frequent', random_state=0, add_indicator=True)\n",
    "indicator_cols = [feat+'_ind' for feat in features]\n",
    "for col in indicator_cols:\n",
    "    data[col] = 0\n",
    "data[features+indicator_cols] = imp.fit_transform(data[features])\n",
    "data[features] = data[features].astype(np.int16)\n",
    "data[indicator_cols] = data[indicator_cols].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test  = data[data.target == -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "features_enc = [col + '_enc' for col in features]\n",
    "for col in features:\n",
    "    catenc = CatBoostEncoder(return_df=False, random_state=0)\n",
    "    train[col + '_enc'] = catenc.fit_transform(train.loc[:, col].astype('str'), train.target.values)\n",
    "    test[col + '_enc'] = catenc.transform(test.loc[:, col].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_feature_columns = [SparseFeat(feat, train[feat].nunique() + 1, embedding_dim=4) for feat in (features+indicator_cols)]\n",
    "linear_feature_columns = [DenseFeat(feat, 1) for feat in (features_enc)]\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    def fallback_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return roc_auc_score(y_true, y_pred)\n",
    "        except:\n",
    "            return 0.5\n",
    "    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1 / (2. ** (x - 1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma ** (x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "\n",
    "    def clr(self):\n",
    "        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n",
    "        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(\n",
    "                self.clr_iterations)\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "\n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['target']\n",
    "N_Splits = 10\n",
    "Verbose = 1\n",
    "Epochs = 50\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "grid_params = {\n",
    "    'dnn_dropout': [0.0, 0.1, 0.2],\n",
    "    'dnn_hidden_units': [(256,), (512,), (256, 256), (512, 512)],\n",
    "    'linear': [linear_feature_columns, linear_feature_columns + dnn_feature_columns],\n",
    "    'sparse': [dnn_feature_columns, linear_feature_columns + dnn_feature_columns],\n",
    "    'batch_size': [128, 256, 512],\n",
    "}\n",
    "list_params = list(ParameterSampler(grid_params,\n",
    "                                    n_iter=20,\n",
    "                                    random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_perf = []\n",
    "\n",
    "for param in list_params:\n",
    "\n",
    "    oof_pred_deepfm = np.zeros((len(train), ))\n",
    "    y_pred_deepfm = np.zeros((len(test),))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_Splits, shuffle=True, random_state=SEED)\n",
    "    for fold, (tr_ind, val_ind) in enumerate(skf.split(train, train[target])):\n",
    "        X_train, X_val = train[features+features_enc+indicator_cols].iloc[tr_ind], train[features+features_enc+indicator_cols].iloc[val_ind]\n",
    "        y_train, y_val = train[target].iloc[tr_ind], train[target].iloc[val_ind]\n",
    "        train_model_input = {name:X_train[name] for name in feature_names}\n",
    "        val_model_input = {name:X_val[name] for name in feature_names}\n",
    "        test_model_input = {name:test[name] for name in feature_names}\n",
    "        model = DeepFM(param['linear'], param['sparse'],\n",
    "                       dnn_hidden_units=param['dnn_hidden_units'], dnn_dropout=param['dnn_dropout'], dnn_use_bn=False, task='binary')\n",
    "        model.compile(\"adam\", \"binary_crossentropy\", metrics=[auc], )\n",
    "        es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=4, verbose=Verbose, mode='max', baseline=None, restore_best_weights=True)\n",
    "        sb = callbacks.ModelCheckpoint('./nn_model.w8', save_weights_only=True, save_best_only=True, verbose=Verbose)\n",
    "        clr = CyclicLR(base_lr=0.00001 / 100, max_lr = 0.0001, \n",
    "                           step_size= int(1.0*(test.shape[0])/1024) , mode='exp_range',\n",
    "                           gamma=1., scale_fn=None, scale_mode='cycle')\n",
    "        history = model.fit(train_model_input, y_train,\n",
    "                            validation_data=(val_model_input, y_val),\n",
    "                            batch_size=param['batch_size'], epochs=Epochs, verbose=Verbose,\n",
    "                            callbacks=[es, sb, clr],)\n",
    "        model.load_weights('./nn_model.w8')\n",
    "        val_pred = model.predict(val_model_input, batch_size=param['batch_size'])\n",
    "        print(f\"validation AUC fold {fold+1} : {round(roc_auc_score(y_val, val_pred), 5)}\")\n",
    "        oof_pred_deepfm[val_ind] = val_pred.ravel()\n",
    "        y_pred_deepfm += model.predict(test_model_input, batch_size=param['batch_size']).ravel() / (N_Splits)\n",
    "        K.clear_session()\n",
    "    cv_perf.append(round(roc_auc_score(train.target.values, oof_pred_deepfm), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 50 best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['target']\n",
    "N_Splits = 50\n",
    "Verbose = 1\n",
    "Epochs = 50\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred_deepfm = np.zeros((len(train), ))\n",
    "y_pred_deepfm = np.zeros((len(test),))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_Splits, shuffle=True, random_state=SEED)\n",
    "for fold, (tr_ind, val_ind) in enumerate(skf.split(train, train[target])):\n",
    "    X_train, X_val = train[features+features_enc+indicator_cols].iloc[tr_ind], train[features+features_enc+indicator_cols].iloc[val_ind]\n",
    "    y_train, y_val = train[target].iloc[tr_ind], train[target].iloc[val_ind]\n",
    "    train_model_input = {name:X_train[name] for name in feature_names}\n",
    "    val_model_input = {name:X_val[name] for name in feature_names}\n",
    "    test_model_input = {name:test[name] for name in feature_names}\n",
    "    model = DeepFM(linear_feature_columns, linear_feature_columns + dnn_feature_columns,\n",
    "                   dnn_hidden_units=(256,), dnn_dropout=0.0, dnn_use_bn=False, task='binary')\n",
    "    model.compile(\"adam\", \"binary_crossentropy\", metrics=[auc], )\n",
    "    es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=4, verbose=Verbose, mode='max', baseline=None, restore_best_weights=True)\n",
    "    sb = callbacks.ModelCheckpoint('./nn_model.w8', save_weights_only=True, save_best_only=True, verbose=Verbose)\n",
    "    clr = CyclicLR(base_lr=0.00001 / 100, max_lr = 0.0001, \n",
    "                       step_size= int(1.0*(test.shape[0])/1024) , mode='exp_range',\n",
    "                       gamma=1., scale_fn=None, scale_mode='cycle')\n",
    "    history = model.fit(train_model_input, y_train,\n",
    "                        validation_data=(val_model_input, y_val),\n",
    "                        batch_size=512, epochs=Epochs, verbose=Verbose,\n",
    "                        callbacks=[es, sb, clr],)\n",
    "    model.load_weights('./nn_model.w8')\n",
    "    val_pred = model.predict(val_model_input, batch_size=512)\n",
    "    print(f\"validation AUC fold {fold+1} : {round(roc_auc_score(y_val, val_pred), 5)}\")\n",
    "    oof_pred_deepfm[val_ind] = val_pred.ravel()\n",
    "    y_pred_deepfm += model.predict(test_model_input, batch_size=512).ravel() / (N_Splits)\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"OOF AUC : {round(roc_auc_score(train.target.values, oof_pred_deepfm), 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = test.id.values\n",
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': test_idx,\n",
    "    'target': y_pred_deepfm\n",
    "})\n",
    "submission.to_csv(\"submission_deepfm_cv_50.csv\", index=False)\n",
    "print(\"Submission file saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('oof_pred_deepfm_cv_50.npy',oof_pred_deepfm)\n",
    "np.save('y_pred_deepfm_cv_50.npy',    y_pred_deepfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
